{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "63aOEusN1Tgf"
   },
   "source": [
    "# Supervised image denoising"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uCIAhtbr1Yhs"
   },
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "2xzQSB-t95mT"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from os import listdir\n",
    "from os.path import join\n",
    "from torchvision.transforms import Compose, ToTensor, ToPILImage, Resize, Lambda, Normalize, Grayscale\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from math import log10\n",
    "from tqdm.notebook import tqdm\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3fvdQA9THZPs"
   },
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ckroXmQgHbCb",
    "outputId": "fcb34906-af70-44f5-870c-5cd42bc9c894"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************************************\n",
      "size of original_train :  (2000, 64, 64)\n",
      "size of noise_train    :  (2000, 64, 64)\n",
      "*************************************************\n",
      "size of original_test :  (900, 64, 64)\n",
      "size of noise_test    :  (900, 64, 64)\n",
      "*************************************************\n",
      "number of training image : 2000\n",
      "height of training image : 64\n",
      "width of training image  : 64\n",
      "*************************************************\n",
      "number of testing image : 900\n",
      "height of testing image : 64\n",
      "width of testing image  : 64\n",
      "*************************************************\n"
     ]
    }
   ],
   "source": [
    "directory_data  = './'\n",
    "filename_data   = 'assignment_07_data.npz'\n",
    "data            = np.load(os.path.join(directory_data, filename_data))\n",
    "\n",
    "\n",
    "original_train = data['original_train'] \n",
    "noise_train    = data['noise_train']\n",
    "\n",
    "original_test = data['original_test'] \n",
    "noise_test    = data['noise_test']\n",
    "\n",
    "print('*************************************************')\n",
    "print('size of original_train : ', original_train.shape)\n",
    "print('size of noise_train    : ', noise_train.shape)\n",
    "print('*************************************************')\n",
    "print('size of original_test : ', original_test.shape)\n",
    "print('size of noise_test    : ', noise_test.shape)\n",
    "print('*************************************************')\n",
    "print('number of training image :', original_train.shape[0])\n",
    "print('height of training image :', original_train.shape[1])\n",
    "print('width of training image  :', original_train.shape[2])\n",
    "print('*************************************************')\n",
    "print('number of testing image :', original_test.shape[0])\n",
    "print('height of testing image :', original_test.shape[1])\n",
    "print('width of testing image  :', original_test.shape[2])\n",
    "print('*************************************************')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-1hicXomGrkw"
   },
   "source": [
    "## Hyper parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "3GAHfVd2G0ev"
   },
   "outputs": [],
   "source": [
    "device        = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "number_epoch    = 200\n",
    "size_minibatch  = 50\n",
    "learning_rate   = 0.1\n",
    "momentum        = 0.9\n",
    "weight_decay    = 0.0001"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "asN2O6HH1cdK"
   },
   "source": [
    "## Costumize dataloader for pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "nHWHWu9p-Bs5"
   },
   "outputs": [],
   "source": [
    "class dataset (Dataset):\n",
    "    def  __init__(self, original,noise):\n",
    "\n",
    "        self.original = original\n",
    "        self.noise    = noise\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "\n",
    "        original    = self.original[index]\n",
    "        noise       = self.noise[index]\n",
    "    \n",
    "        original   = torch.FloatTensor(original).unsqueeze(dim=0)\n",
    "        noise      = torch.FloatTensor(noise).unsqueeze(dim=0)\n",
    "\n",
    "\n",
    "        return (original , noise)\n",
    "  \n",
    "    def __len__(self):\n",
    "\n",
    "        return self.original.shape[0]\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W1RYZQkkJm78"
   },
   "source": [
    "## Construct datasets and dataloaders for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "JwKkQ4Hw-Fkb"
   },
   "outputs": [],
   "source": [
    "dataset_train = dataset(original_train, noise_train) \n",
    "dataset_test  = dataset(original_test, noise_test) \n",
    "\n",
    "dataloader_train = DataLoader(dataset_train, batch_size=size_minibatch, shuffle=True, drop_last=True, num_workers=0)\n",
    "dataloader_test  = DataLoader(dataset_test,  batch_size=size_minibatch, shuffle=False, drop_last=True, num_workers=0) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Shape of the data with data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************************************************\n",
      "shape of the original image in the training dataset: torch.Size([1, 64, 64])\n",
      "shape of the noisy image in the training dataset: torch.Size([1, 64, 64])\n",
      "************************************************************\n",
      "shape of the original image in the testing dataset: torch.Size([1, 64, 64])\n",
      "shape of the noisy image in the testing dataset: torch.Size([1, 64, 64])\n",
      "************************************************************\n"
     ]
    }
   ],
   "source": [
    "(original_train, noise_train)   = dataset_train[0]\n",
    "(original_test, noise_test)     = dataset_test[0]\n",
    "\n",
    "print('************************************************************')\n",
    "print('shape of the original image in the training dataset:', original_train.shape)\n",
    "print('shape of the noisy image in the training dataset:', noise_train.shape)\n",
    "print('************************************************************')\n",
    "print('shape of the original image in the testing dataset:', original_test.shape)\n",
    "print('shape of the noisy image in the testing dataset:', noise_test.shape)\n",
    "print('************************************************************')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8ngJeHXH2dfj"
   },
   "source": [
    "## Class for the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "PjlHwUOV-UCh"
   },
   "outputs": [],
   "source": [
    "class Network(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Network,self).__init__()\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Encoder\n",
    "        # -------------------------------------------------\n",
    "        self.e_layer1 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=1, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),  \n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(8),\n",
    "        )\n",
    "        \n",
    "        self.e_layer2 = nn.Sequential(\n",
    "                        nn.Conv2d(in_channels=8, out_channels=16, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                        nn.MaxPool2d(2,2),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(16),\n",
    "        )\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Decoder\n",
    "        # -------------------------------------------------\n",
    "        self.d_layer1 = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                        nn.Conv2d(in_channels=16, out_channels=8, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                        nn.ReLU(),\n",
    "                        nn.BatchNorm2d(8),\n",
    "        )\n",
    "        \n",
    "        self.d_layer2 = nn.Sequential(\n",
    "                        nn.Upsample(scale_factor=2, mode='bilinear', align_corners=False),\n",
    "                        nn.Conv2d(in_channels=8, out_channels=1, kernel_size=3, stride=1, padding=1, bias=True),\n",
    "                        nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "        # -------------------------------------------------\n",
    "        # Network\n",
    "        # -------------------------------------------------\n",
    "        self.network = nn.Sequential(\n",
    "                        self.e_layer1,\n",
    "                        self.e_layer2,\n",
    "                        self.d_layer1, \n",
    "                        self.d_layer2,\n",
    "        )\n",
    "\n",
    "        self.initialize_weight()\n",
    "\n",
    "    def forward(self,x):\n",
    "    \n",
    "        out = self.network(x)\n",
    "      \n",
    "        return out\n",
    "\n",
    "    # ======================================================================\n",
    "    # initialize weights\n",
    "    # ======================================================================\n",
    "    def initialize_weight(self):\n",
    "            \n",
    "        for m in self.network.modules():\n",
    "            \n",
    "            if isinstance(m, nn.Conv2d):\n",
    "\n",
    "                nn.init.constant_(m.weight, 0.1) \n",
    "                \n",
    "                if m.bias is not None:\n",
    "\n",
    "                    nn.init.constant_(m.bias, 1)\n",
    "                    pass\n",
    "                    \n",
    "            elif isinstance(m, nn.BatchNorm2d):\n",
    "                \n",
    "                nn.init.constant_(m.weight, 1)\n",
    "                nn.init.constant_(m.bias, 1)\n",
    "                \n",
    "            elif isinstance(m, nn.Linear):\n",
    "                \n",
    "                nn.init.constant_(m.weight, 0.1) \n",
    "\n",
    "                if m.bias is not None:\n",
    "                    \n",
    "                    nn.init.constant_(m.bias, 1)\n",
    "                    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTXZnsrGLoxg"
   },
   "source": [
    "## Build the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "xsGGOsXKLuc1"
   },
   "outputs": [],
   "source": [
    "model = Network().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate, momentum=momentum , weight_decay=weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yE9LChkQ5G2"
   },
   "source": [
    "## Compute prediction (denoised image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "9mgS8kzGQ502"
   },
   "outputs": [],
   "source": [
    "def compute_prediction(model, input):\n",
    "\n",
    "    denoise = model(input)\n",
    "\n",
    "    return denoise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UQVz0ChdM9KL"
   },
   "source": [
    "## Compute loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XbvdtlxKNAmm"
   },
   "outputs": [],
   "source": [
    "def compute_loss(noise, original):\n",
    "\n",
    "    criterion   = nn.MSELoss()\n",
    "    loss        = criterion(noise, original)\n",
    "    loss_value  = loss.item()\n",
    "\n",
    "    return loss, loss_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lKGc41X7NZ_M"
   },
   "source": [
    "## Compute PSNR metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "SVXKX82D9k20"
   },
   "outputs": [],
   "source": [
    "def compute_PSNR (loss):\n",
    "\n",
    "    if (loss==0.):\n",
    "        PSNR=100\n",
    "    else :\n",
    "        PSNR=10*log10(1/loss)\n",
    "\n",
    "    return PSNR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9UIl4gCp2hE6"
   },
   "source": [
    "## Variable for the learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NXs-w_99-cuZ"
   },
   "outputs": [],
   "source": [
    "loss_mean_train     = np.zeros(number_epoch)\n",
    "loss_std_train      = np.zeros(number_epoch)\n",
    "PSNR_mean_train     = np.zeros(number_epoch)\n",
    "PSNR_std_train      = np.zeros(number_epoch)\n",
    "\n",
    "loss_mean_test      = np.zeros(number_epoch)\n",
    "loss_std_test       = np.zeros(number_epoch)\n",
    "PSNR_mean_test      = np.zeros(number_epoch)\n",
    "PSNR_std_test       = np.zeros(number_epoch)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7HWScczDn6S"
   },
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Q3p34UDlDqWg"
   },
   "outputs": [],
   "source": [
    "def train(model, dataloader):\n",
    "\n",
    "    loss_epoch      = []\n",
    "    psnr_epoch      = []\n",
    "\n",
    "    model = model.train()\n",
    "    \n",
    "    for index_batch, (original, noise) in enumerate(dataloader):\n",
    "        \n",
    "        original = original.to(device)\n",
    "        noise    = noise.to(device)\n",
    "        # ================================================================================ \n",
    "        # complete the following codes \n",
    "        # \n",
    "       \n",
    "        denoise             = compute_prediction( model, noise )\n",
    "        loss, loss_value    = compute_loss(denoise, original)\n",
    "        # ================================================================================ \n",
    "        psnr                = compute_PSNR(loss_value)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_epoch.append(loss_value)\n",
    "        psnr_epoch.append(psnr)\n",
    "\n",
    "    loss_mean_epoch     = np.mean(loss_epoch)\n",
    "    loss_std_epoch      = np.std(loss_epoch)\n",
    "\n",
    "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
    "    psnr_std_epoch  = np.std(psnr_epoch)\n",
    "\n",
    "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
    "    psnr        = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
    "\n",
    "    return (loss, psnr)    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C783v5uJE1Y9"
   },
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "xJz-987xE38P"
   },
   "outputs": [],
   "source": [
    "def test(model, dataloader):\n",
    "\n",
    "    loss_epoch      = []\n",
    "    psnr_epoch      = []\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "    for index_batch, (original, noise) in enumerate(dataloader):\n",
    "\n",
    "        original = original.to(device)\n",
    "        noise    = noise.to(device)\n",
    "        \n",
    "        # ================================================================================ \n",
    "        # complete the following codes \n",
    "        # \n",
    "        denoise             = compute_prediction(model, noise)\n",
    "        loss, loss_value    = compute_loss(denoise, original)\n",
    "        # ================================================================================ \n",
    "        psnr                = compute_PSNR(loss_value)\n",
    "\n",
    "        loss_epoch.append(loss_value)\n",
    "        psnr_epoch.append(psnr)\n",
    "\n",
    "    loss_mean_epoch     = np.mean(loss_epoch)\n",
    "    loss_std_epoch      = np.std(loss_epoch)\n",
    "\n",
    "    psnr_mean_epoch = np.mean(psnr_epoch)\n",
    "    psnr_std_epoch  = np.std(psnr_epoch)\n",
    "\n",
    "    loss        = {'mean' : loss_mean_epoch, 'std' : loss_std_epoch}\n",
    "    psnr        = {'mean' : psnr_mean_epoch, 'std' : psnr_std_epoch}\n",
    "\n",
    "    return (loss, psnr)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j9ZcyzVkFsex"
   },
   "source": [
    "## train and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 48,
     "referenced_widgets": [
      "615b93ce41b942dca1478631e8392279",
      "7578d2a5f0af4ba78a765bc38535c98d",
      "3ed9a840122c424d8aa9909122696711",
      "ae11af637c7a45feabdf6211993b2a18",
      "cf2f6798487e4bb984eea0153ad5ef41",
      "b934d7dec0ff49feb04fb5ffe1a6e91e",
      "e88cb30590ab474691856d3b14feb67e",
      "edeeb015d40d4e91bd739ff9d5de0649",
      "e60dc2f6fa774b1d807a4b77be08548b",
      "fafd0841d1974cccb4b46231de87f52b",
      "dbcad030067f46c29ca184fe962e7851"
     ]
    },
    "id": "l6Qtqgv8-fMW",
    "outputId": "200d8680-f289-4440-ad95-1ff0709e5a1b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af2a0f464a35436dab55c4a8243e9ff1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(HTML(value=''), FloatProgress(value=0.0, max=200.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\fromnumeric.py:3372: RuntimeWarning: Mean of empty slice.\n",
      "  return _methods._mean(a, axis=axis, dtype=dtype,\n",
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:233: RuntimeWarning: Degrees of freedom <= 0 for slice\n",
      "  ret = _var(a, axis=axis, dtype=dtype, out=out, ddof=ddof,\n",
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:194: RuntimeWarning: invalid value encountered in true_divide\n",
      "  arrmean = um.true_divide(\n",
      "C:\\anaconda\\lib\\site-packages\\numpy\\core\\_methods.py:226: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n"
     ]
    }
   ],
   "source": [
    "# ================================================================================\n",
    "# \n",
    "# iterations for epochs\n",
    "#\n",
    "# ================================================================================\n",
    "for i in tqdm(range(number_epoch)):\n",
    "    \n",
    "    # ================================================================================\n",
    "    # \n",
    "    # training\n",
    "    #\n",
    "    # ================================================================================\n",
    "    (loss_train, psnr_train) = train(model, dataloader_train)\n",
    "\n",
    "    loss_mean_train[i]      = loss_train['mean']\n",
    "    loss_std_train[i]       = loss_train['std']\n",
    "\n",
    "    PSNR_mean_train[i]  = psnr_train['mean']\n",
    "    PSNR_std_train[i]   = psnr_train['std']\n",
    "\n",
    "    # ================================================================================\n",
    "    # \n",
    "    # testing\n",
    "    #\n",
    "    # ================================================================================\n",
    "    (loss_test, psnr_test) = test(model, dataloader_test)\n",
    "\n",
    "    loss_mean_test[i]      = loss_test['mean']\n",
    "    loss_std_test[i]       = loss_test['std']\n",
    "\n",
    "    PSNR_mean_test[i]  = psnr_test['mean']\n",
    "    PSNR_std_test[i]   = psnr_test['std']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I9RWomhwgpiM"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zRwqJtn9glD5"
   },
   "source": [
    "# DO NOT MODIFY THE CODES FROM HERE, BUT EXECUTE THEM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1ukjE6pAgqlq"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVugi_Pi256d"
   },
   "source": [
    "## Plot functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "Tp50r3lh-o-P"
   },
   "outputs": [],
   "source": [
    "def plot_data_grid(data, index_data, nRow, nCol):\n",
    "    \n",
    "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
    "\n",
    "    for i in range(nRow):\n",
    "        for j in range(nCol):\n",
    "\n",
    "            k       = i * nCol + j\n",
    "            index   = index_data[k]\n",
    "\n",
    "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, j].xaxis.set_visible(False)\n",
    "            axes[i, j].yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "0bEBS7q5-jYh"
   },
   "outputs": [],
   "source": [
    "def plot_data_tensor_grid(data, index_data, nRow, nCol):\n",
    "    \n",
    "    fig, axes = plt.subplots(nRow, nCol, constrained_layout=True, figsize=(nCol * 3, nRow * 3))\n",
    "\n",
    "    data = data.detach().cpu().squeeze(axis=1)\n",
    "\n",
    "    for i in range(nRow):\n",
    "        for j in range(nCol):\n",
    "\n",
    "            k       = i * nCol + j\n",
    "            index   = index_data[k]\n",
    "\n",
    "            axes[i, j].imshow(data[index], cmap='gray', vmin=0, vmax=1)\n",
    "            axes[i, j].xaxis.set_visible(False)\n",
    "            axes[i, j].yaxis.set_visible(False)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "w-5kFhCn-maa"
   },
   "outputs": [],
   "source": [
    "def plot_curve_error(data_mean, data_std, x_label, y_label, title):\n",
    "\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    plt.title(title)\n",
    "\n",
    "    alpha = 0.3\n",
    "    \n",
    "    plt.plot(range(len(data_mean)), data_mean, '-', color = 'red')\n",
    "    plt.fill_between(range(len(data_mean)), data_mean - data_std, data_mean + data_std, facecolor = 'blue', alpha = alpha) \n",
    "    \n",
    "    plt.xlabel(x_label)\n",
    "    plt.ylabel(y_label)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "6x-lgRuxlWY5"
   },
   "outputs": [],
   "source": [
    "def print_curve(data, index):\n",
    "    \n",
    "    for i in range(len(index)):\n",
    "\n",
    "        idx = index[i]\n",
    "        val = data[idx]\n",
    "\n",
    "        print('index = %2d, value = %12.10f' % (idx, val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "jabaN70hlZA1"
   },
   "outputs": [],
   "source": [
    "def get_data_last(data, index_start):\n",
    "\n",
    "    data_last = data[index_start:]\n",
    "\n",
    "    return data_last"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "aAk1QIYMleCQ"
   },
   "outputs": [],
   "source": [
    "def get_max_last_range(data, index_start):\n",
    "\n",
    "    data_range = get_data_last(data, index_start)\n",
    "    value = data_range.max()\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "OXluWDRPOErr"
   },
   "outputs": [],
   "source": [
    "def get_min_last_range(data, index_start):\n",
    "\n",
    "    data_range = get_data_last(data, index_start)\n",
    "    value = data_range.min()\n",
    "\n",
    "    return value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-KZrNorBOIzA"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NCp_QnbqhIlv"
   },
   "source": [
    "# functions for presenting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dS6Lkh9LOJop"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "id": "yJI8yG5xmBEA"
   },
   "outputs": [],
   "source": [
    "def function_result_01():\n",
    "\n",
    "    print('[plot examples of the training clean images]')\n",
    "    print('') \n",
    "\n",
    "    nRow = 5 \n",
    "    nCol = 3\n",
    "    index_data  = np.arange(0, nRow * nCol)\n",
    "    original_train = dataset_train.original[0 : index_data]\n",
    "\n",
    "    plot_data_grid(original_train, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "id": "mBizLSHz-4kV"
   },
   "outputs": [],
   "source": [
    "def function_result_02():\n",
    "\n",
    "    print('[plot examples of the training noisy images]')\n",
    "    print('') \n",
    "    \n",
    "    nRow = 5\n",
    "    nCol = 4\n",
    "    index_data  = np.arange(0, nRow * nCol)\n",
    "    noise_train = dataset_train.noise[index_data]\n",
    "\n",
    "    plot_data_grid(noise_train, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "id": "zK4jOaFz-7Ih"
   },
   "outputs": [],
   "source": [
    "def function_result_03():\n",
    "\n",
    "    print('[plot examples of the training denoising results]')\n",
    "    print('') \n",
    "\n",
    "    nRow = 5\n",
    "    nCol = 4\n",
    "    index_data          = np.arange(0, nRow * nCol)\n",
    "    image_train         = torch.FloatTensor(dataset_train.original[index_data]).unsqueeze(dim=1).to(device)\n",
    "    prediction_train    = compute_prediction(model, image_train)\n",
    "    \n",
    "    plot_data_tensor_grid(prediction_train, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "id": "Jyif5Mul_JA3"
   },
   "outputs": [],
   "source": [
    "def function_result_04():\n",
    "\n",
    "    print('[plot examples of the testing clean images]')\n",
    "    print('') \n",
    "    \n",
    "    nRow = 5\n",
    "    nCol = 4\n",
    "    index_data = np.arange(0, nRow * nCol)\n",
    "    original_test = dataset_test.original[index_data]\n",
    "\n",
    "    plot_data_grid(original_test, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "id": "c1R8cJd9_Mod"
   },
   "outputs": [],
   "source": [
    "def function_result_05():\n",
    "\n",
    "    print('[plot examples of the testing noise images]')\n",
    "    print('') \n",
    "\n",
    "    nRow = 5\n",
    "    nCol = 4\n",
    "    index_data = np.arange(0, nRow * nCol)\n",
    "    noise_test = dataset_test.noise[index_data]\n",
    "\n",
    "    plot_data_grid(noise_test, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "id": "s3mHkTGHtv_g"
   },
   "outputs": [],
   "source": [
    "def function_result_06():\n",
    "\n",
    "    print('[plot examples of the testing denoising results]')\n",
    "    print('') \n",
    "\n",
    "    nRow = 5\n",
    "    nCol = 4\n",
    "    index_data      = np.arange(0, nRow * nCol)\n",
    "    image_test      = torch.FloatTensor(dataset_test.original[index_data]).unsqueeze(dim=1).to(device)\n",
    "    prediction_test = compute_prediction(model, image_test)\n",
    "\n",
    "    plot_data_tensor_grid(prediction_test, index_data, nRow, nCol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "id": "-yQPW3wPsr9L"
   },
   "outputs": [],
   "source": [
    "def function_result_07():\n",
    "\n",
    "    print('[plot the training loss]')\n",
    "    print('') \n",
    "\n",
    "    plot_curve_error(loss_mean_train, loss_std_train, 'epoch', 'loss', 'loss (training)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "id": "Lv8yfa28AfLj"
   },
   "outputs": [],
   "source": [
    "def function_result_08():\n",
    "\n",
    "    print('[plot the training PSNR]')\n",
    "    print('') \n",
    "    \n",
    "    plot_curve_error(PSNR_mean_train, PSNR_std_train, 'epoch', 'PSNR', 'PSNR (training)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "id": "OQwA14KhBF7R"
   },
   "outputs": [],
   "source": [
    "def function_result_09():\n",
    "    \n",
    "    print('[plot the testing loss]')\n",
    "    print('') \n",
    "    \n",
    "    plot_curve_error(loss_mean_test, loss_std_test, 'epoch', 'loss', 'loss (testing)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "id": "lIipA2maBQjm"
   },
   "outputs": [],
   "source": [
    "def function_result_10():\n",
    "    \n",
    "    print('[plot the testing PSNR]') \n",
    "    print('') \n",
    "    \n",
    "    plot_curve_error(PSNR_mean_test, PSNR_std_test, 'epoch', 'PSNR', 'PSNR (testing)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "id": "rkV-iWvbQ8Vw"
   },
   "outputs": [],
   "source": [
    "def function_result_11():\n",
    "    \n",
    "    print('[print the training loss at the last 10 epochs]')\n",
    "    print('') \n",
    "\n",
    "    data_last = get_data_last(loss_mean_train, -10)\n",
    "    index = np.arange(0, 10)\n",
    "    print_curve(data_last, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "id": "Ay2Sg3FFQ_TX"
   },
   "outputs": [],
   "source": [
    "def function_result_12():\n",
    "    \n",
    "    print('[print the training PSNR at the last 10 epochs]')\n",
    "    print('') \n",
    "    \n",
    "    data_last = get_data_last(PSNR_mean_train, -10)\n",
    "    index = np.arange(0, 10)\n",
    "    print_curve(data_last, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "id": "SaocjWCbROVB"
   },
   "outputs": [],
   "source": [
    "def function_result_13():\n",
    "    \n",
    "    print('[print the testing loss at the last 10 epochs]')\n",
    "    print('') \n",
    "    \n",
    "    data_last = get_data_last(loss_mean_test, -10)\n",
    "    index = np.arange(0, 10)\n",
    "    print_curve(data_last, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "id": "YoqxTw8RRPj6"
   },
   "outputs": [],
   "source": [
    "def function_result_14():\n",
    "    \n",
    "    print('[print the testing PSNR at the last 10 epochs]')\n",
    "    print('') \n",
    "    \n",
    "    data_last = get_data_last(PSNR_mean_test, -10)\n",
    "    index = np.arange(0, 10)\n",
    "    print_curve(data_last, index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "id": "sb5WJWYcReyn"
   },
   "outputs": [],
   "source": [
    "def function_result_15():\n",
    "    \n",
    "    print('[print the best training PSNR within the last 10 epochs]')\n",
    "    print('') \n",
    "\n",
    "    value = get_max_last_range(PSNR_mean_train, -10)\n",
    "    print('best training PSNR = %12.10f' % (value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "id": "QtYAue5nRprJ"
   },
   "outputs": [],
   "source": [
    "def function_result_16():\n",
    "    \n",
    "    print('[print the best testing PSNR within the last 10 epochs]')\n",
    "    print('') \n",
    "    \n",
    "    value = get_max_last_range(PSNR_mean_test, -10)\n",
    "    print('best testing PSNR = %12.10f' % (value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "22XygAZhHStf"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7MxxDcR4HW8j"
   },
   "source": [
    "# RESULTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LdjiEN4zI7Sx"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "tSZq5QWcm6VH",
    "outputId": "6290e5b5-4aeb-4516-b741-c2c78765ea9e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "################################################################################\n",
      "#\n",
      "# RESULT # 01\n",
      "#\n",
      "################################################################################\n",
      "\n",
      "[plot examples of the training clean images]\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "only integer scalar arrays can be converted to a scalar index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-160-4c6785a1fe45>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m     \u001b[0meval\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_function\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<string>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-144-68830af1b472>\u001b[0m in \u001b[0;36mfunction_result_01\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mnCol\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mindex_data\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnRow\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mnCol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0moriginal_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdataset_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moriginal\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mindex_data\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mplot_data_grid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moriginal_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnRow\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnCol\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: only integer scalar arrays can be converted to a scalar index"
     ]
    }
   ],
   "source": [
    "number_result = 16\n",
    "\n",
    "for i in range(number_result):\n",
    "\n",
    "    title           = '# RESULT # {:02d}'.format(i+1) \n",
    "    name_function   = 'function_result_{:02d}()'.format(i+1)\n",
    "\n",
    "    print('') \n",
    "    print('################################################################################')\n",
    "    print('#') \n",
    "    print(title)\n",
    "    print('#') \n",
    "    print('################################################################################')\n",
    "    print('') \n",
    "\n",
    "    eval(name_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "assignment_07_solution.ipynb",
   "provenance": []
  },
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "3ed9a840122c424d8aa9909122696711": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e88cb30590ab474691856d3b14feb67e",
      "placeholder": "​",
      "style": "IPY_MODEL_b934d7dec0ff49feb04fb5ffe1a6e91e",
      "value": "100%"
     }
    },
    "615b93ce41b942dca1478631e8392279": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3ed9a840122c424d8aa9909122696711",
       "IPY_MODEL_ae11af637c7a45feabdf6211993b2a18",
       "IPY_MODEL_cf2f6798487e4bb984eea0153ad5ef41"
      ],
      "layout": "IPY_MODEL_7578d2a5f0af4ba78a765bc38535c98d"
     }
    },
    "7578d2a5f0af4ba78a765bc38535c98d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ae11af637c7a45feabdf6211993b2a18": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e60dc2f6fa774b1d807a4b77be08548b",
      "max": 200,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_edeeb015d40d4e91bd739ff9d5de0649",
      "value": 200
     }
    },
    "b934d7dec0ff49feb04fb5ffe1a6e91e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cf2f6798487e4bb984eea0153ad5ef41": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_dbcad030067f46c29ca184fe962e7851",
      "placeholder": "​",
      "style": "IPY_MODEL_fafd0841d1974cccb4b46231de87f52b",
      "value": " 200/200 [14:53&lt;00:00,  4.48s/it]"
     }
    },
    "dbcad030067f46c29ca184fe962e7851": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e60dc2f6fa774b1d807a4b77be08548b": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e88cb30590ab474691856d3b14feb67e": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "edeeb015d40d4e91bd739ff9d5de0649": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "fafd0841d1974cccb4b46231de87f52b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
